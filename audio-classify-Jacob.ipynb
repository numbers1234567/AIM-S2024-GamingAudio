{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from msclap import CLAP\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-fused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty array \n",
    "audio_array = np.empty([])\n",
    "\n",
    "word_detected = False\n",
    "\n",
    "#CLAP model's prediction function\n",
    "def classify(audio):\n",
    "    global audio_array, word_detected\n",
    "    \n",
    "    samplerate, array = audio\n",
    "    \n",
    "    live_array = np.array(array)\n",
    "    audio_array = np.append(audio_array, live_array)\n",
    "    \n",
    "    dimension = audio_array.shape\n",
    "    \n",
    "    \n",
    "    #removes 5 second of audio from array if it's longer than 5 seconds\n",
    "    if((dimension[0]) > (240000)):\n",
    "        audio_array = audio_array[-240000:]\n",
    "    \n",
    "    print(audio_array.shape)\n",
    "    \n",
    "    result = pipe(audio_array, candidate_labels=[\"silence\", \"left\",\"right\",\"reload\"])\n",
    "\n",
    "    #if word is detected or if the audio reaches 5 seconds, \n",
    "    #then reset the audio array to empty\n",
    "    if (word_detected == True):\n",
    "        audio_array = np.empty([1,1])\n",
    "        word_detected = False\n",
    "    \n",
    "    df = pd.DataFrame(result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=classify,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"],streaming=True),\n",
    "    outputs=[gr.Dataframe()],\n",
    "    live=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7884\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24001,)\n",
      "(96001,)\n",
      "(216001,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n",
      "(240000,)\n"
     ]
    }
   ],
   "source": [
    "#Launches Gradio Interface\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
