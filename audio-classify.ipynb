{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pynput import keyboard\n",
    "import time\n",
    "import json\n",
    "from pynput.keyboard import Key, Controller, KeyCode\n",
    "import eng_to_ipa as ipa\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"./clap-ipa\")\n",
    "from clap.encoders import *\n",
    "import torch.nn.functional as F\n",
    "from transformers import DebertaV2Tokenizer, AutoProcessor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "speech_encoder = SpeechEncoder.from_pretrained('anyspeech/clap-ipa-tiny-speech')\n",
    "phone_encoder = PhoneEncoder.from_pretrained('anyspeech/clap-ipa-tiny-phone')\n",
    "phone_encoder.eval().to(device)\n",
    "speech_encoder.eval().to(device)\n",
    "\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('charsiu/IPATokenizer')\n",
    "processor = AutoProcessor.from_pretrained('openai/whisper-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-fused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def ipa_converted_vals(labels, audio):\n",
    "    ipa_val_list = []\n",
    "\n",
    "    for x in range(len(labels)):\n",
    "        start = time.time()\n",
    "        audio_input = processor(audio, return_attention_mask=True, sampling_rate=16000,max_length=32000,return_tensors='pt')\n",
    "        ipa_input = tokenizer(ipa.convert(labels[x], keep_punct=True), return_token_type_ids=False, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            speech_embed = speech_encoder(**audio_input).pooler_output\n",
    "            phone_embed = phone_encoder(**ipa_input).pooler_output\n",
    "\n",
    "        similarity = F.cosine_similarity(speech_embed,phone_embed,dim=-1)\n",
    "        ipa_val_list.append((similarity.cpu().detach().numpy())[0])\n",
    "\n",
    "    return ipa_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the macros from the JSON file\n",
    "with open('macros.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract macros from the loaded data\n",
    "macros = data[\"macros\"]\n",
    "\n",
    "# Creates a controller\n",
    "board = Controller()\n",
    "\n",
    "# Create a dictionary to store macros\n",
    "macro_functions = {}\n",
    "\n",
    "# Iterates over every macro\n",
    "for macro in macros:\n",
    "    # Macro details\n",
    "    name = macro[\"name\"]\n",
    "    keycodes = macro[\"keycodes\"]\n",
    "    delay = macro[\"delay\"]\n",
    "\n",
    "# Defines the macro function\n",
    "    macro_function = lambda keycodes=keycodes, delay=delay: [\n",
    "        # Press the key according to the keycode\n",
    "        (board.press(Key.enter) if keycode == Key.enter else\n",
    "        board.press(Key.space) if keycode == Key.space else\n",
    "        # If keycode is a single character then press that key\n",
    "        board.press(keycode) if len(keycode) == 1 else\n",
    "        # Else if the key is in the form <...> then press that key\n",
    "        board.press(KeyCode.from_vk(int(keycode[1:-1]))),\n",
    "        # Delay\n",
    "        time.sleep(delay),\n",
    "        # Release the key according to the key code\n",
    "        board.release(Key.enter) if keycode == Key.enter else\n",
    "        board.release(Key.space) if keycode == Key.space else\n",
    "        # If keycode is a single character then release that key\n",
    "        board.release(keycode) if len(keycode) == 1 else\n",
    "        # Else if the key is in the form <...> then release that key\n",
    "        board.release(KeyCode.from_vk(int(keycode[1:-1]))))\n",
    "        # Iterate over every keycode in the macro\n",
    "        for keycode in keycodes\n",
    "    ]\n",
    "\n",
    "    # Add the macro function to the dictionary with the macro name as the key\n",
    "    macro_functions[name] = macro_function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input - list of strings, list of corresponding scores\n",
    "#Output - list of dictionaries where 'score' contains score corresponding to 'label' value\n",
    "def joinDictionary (labels, scores):\n",
    "    combinedDictionary = []\n",
    "    dictionary = {'score': 0 ,'label':'test'}\n",
    "    for i in range(len(labels)):\n",
    "        #Create new dictionary for each label\n",
    "        dictionary['score'] = scores[i]\n",
    "        dictionary['label'] = labels[i]\n",
    "        #add new dictionary to combined list\n",
    "        combinedDictionary.append(dictionary.copy())\n",
    "    return combinedDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty array \n",
    "audio_array = np.empty([])\n",
    "\n",
    "word_detected = False\n",
    "\n",
    "actions = [\"silence\"]\n",
    "#scores = [0.998,0.01,0.22]\n",
    "for x in macro_functions.keys():\n",
    "    actions.append(x)\n",
    "\n",
    "#actions = [\"nothing\",\"clap\",\"snap\",]\n",
    "\n",
    "\n",
    "#CLAP model's prediction function\n",
    "def classify(audio):\n",
    "    global audio_array, word_detected, actions\n",
    "    i = 0\n",
    "    \n",
    "    samplerate, array = audio\n",
    "    \n",
    "    #converts the input live audio array to numpy array and appends it to current audio array\n",
    "    live_array = np.array(array)\n",
    "    audio_array = np.append(audio_array, live_array)\n",
    "    \n",
    "    dimension = audio_array.shape\n",
    "    \n",
    "    \n",
    "    #removes 5 second of audio from array if it's longer than 5 seconds\n",
    "    if((dimension[0]) > (240000)):\n",
    "        audio_array = audio_array[-240000:]\n",
    "        print(\"Audio size: \", audio_array.shape)\n",
    "    \n",
    "    print(actions)\n",
    "\n",
    "    #Pass audio to model for predictions\n",
    "    result = joinDictionary(actions, ipa_converted_vals(actions, audio_array))\n",
    "\n",
    "    print(result)\n",
    "    \n",
    "    #Formats the result to a dataframe and retrives the highest scoring label\n",
    "    df = pd.DataFrame(result)\n",
    "    max = df.idxmax(numeric_only=True)\n",
    "    index = int(max[0])\n",
    "    word = df.iat[index,1]\n",
    "    print(df)\n",
    "    print(word)\n",
    "    \n",
    "    #Checks if the highest scored label was an action label\n",
    "    '''if word != \"nothing\":\n",
    "        word_detected = True\n",
    "        print(\"word was detected: \", word)\n",
    "        print(\"pressing macros...\")\n",
    "        macro_functions[word]()'''\n",
    "\n",
    "    if word != \"silence\":\n",
    "        word_detected = True\n",
    "        print(\"word was detected: \", word)\n",
    "        print(\"pressing macros...\")\n",
    "        macro_functions[word]()\n",
    "        \n",
    "   \n",
    "    #if word is detected or if the audio reaches 5 seconds, \n",
    "    #then reset the audio array to empty\n",
    "    if (word_detected == True):\n",
    "        audio_array = np.empty([1,1])\n",
    "        print(\"All contents of audio array was removed.\")\n",
    "        word_detected = False\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=classify,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"],streaming=True),\n",
    "    outputs=[gr.Dataframe()],\n",
    "    live=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launches Gradio Interface\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
